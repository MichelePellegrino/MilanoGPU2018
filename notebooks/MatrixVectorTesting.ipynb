{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for accessing CUDA\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no, changed in October by Andr√© Brodtkorb\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_tests, run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Timer import Timer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python version 3.6.6 (default, Sep 12 2018, 18:26:19) \n",
      "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
      "Registering context in user workspace\n",
      "Creating context\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (9, 1, 0)\n",
      "Driver version 10000\n",
      "Using 'Tesla K80' GPU\n",
      " => compute capability: (3, 7)\n",
      " => memory: 10455 / 11441 MB available\n",
      "Created context handle <31985072>\n",
      "Using CUDA cache dir /home/ubuntu/jupyter_notebooks/Michele_Pellegrino/MilanoGPU2018/notebooks/cuda_cache\n"
     ]
    }
   ],
   "source": [
    "%setup_logging\n",
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols) {\n",
    "    // Horizontal threads better than vertical threads\n",
    "    unsigned int j = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    \n",
    "    //Out of bounds check\n",
    "    if (j > a_rows) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    //Compute inner product of row of A with column of B\n",
    "    float sum = 0.0f;\n",
    "    for (int i=0; i<a_cols; ++i) {\n",
    "        unsigned int k = j*a_cols + i;\n",
    "        sum += A[k] * b[i];\n",
    "    }\n",
    "    \n",
    "    //Write to global memory\n",
    "    c[j] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "kernel = module.get_function(\"matrixVectorKernel\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector(a, b):\n",
    "    \n",
    "    context.synchronize()\n",
    "    \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    c = np.empty((a.shape[0], 1), dtype=np.float32)\n",
    "    \n",
    "    with Timer(\"Allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        c_g = GPUArray(c.shape, np.float32)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"Upload\") as t:\n",
    "        a_g.set(a)\n",
    "        b_g.set(b)\n",
    "        context.synchronize()\n",
    "        \n",
    "    #Allocate output data\n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (128, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(c.shape[0] / 128)), 1, 1)\n",
    "    print(\"Block size is \" + str(block_size))\n",
    "    print(\"Grid size is \" + str(grid_size))\n",
    "    #Execute program on device\n",
    "    \n",
    "    with Timer(\"Execution\") as t:\n",
    "        kernel(c_g, a_g, b_g, np.int32(a.shape[0]), np.int32(a.shape[1]), block=block_size, grid=grid_size)\n",
    "        context.synchronize()\n",
    "    \n",
    "    #Copy data from device to host\n",
    "    c_g.get(c)\n",
    "    return c \n",
    "\n",
    "    # Make other tests for the execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocation: 1.788378 ms\n",
      "Upload: 55.014372 ms\n",
      "Execution: 34.315109 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block size is (128, 1, 1)\n",
      "Grid size is (79, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Size of our test\n",
    "test_size = (10000, 10000)\n",
    "\n",
    "#Create test input / output data\n",
    "a = np.random.random(test_size).astype(np.float32)\n",
    "b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "c = gpuMatrixVector(a, b)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.subplot(1,3,1)\n",
    "# plt.imshow(a)\n",
    "# plt.subplot(1,3,2)\n",
    "# plt.imshow(b)\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.imshow(c)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad = 30.949707031250000000000000000000\n",
      "Per element error: 0.003094970703125\n"
     ]
    }
   ],
   "source": [
    "#Compute reference using Numpy\n",
    "c_ref = np.dot(a, b)\n",
    "\n",
    "#Sum of absolute differences\n",
    "sad = np.sum(np.abs(c - c_ref))\n",
    "\n",
    "#Print result\n",
    "# print(\"C   = \", c)\n",
    "# print(\"Ref = \", c_ref)\n",
    "print(\"Sad = %.30f\" % sad)\n",
    "print(\"Per element error: \" + str(sad / test_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tests()\n",
    "\n",
    "def test_gpuMatrixVector():\n",
    "    # Test matrix 1x1\n",
    "    a = np.ones((1,1), dtype=np.float32)\n",
    "    b = 2*np.ones((1,1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(2.0)\n",
    "    # Test inner product 1x1\n",
    "    a = np.ones((1,2), dtype=np.float32)\n",
    "    b = 2*np.ones((2,1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(4.0)\n",
    "    # Test general matrix\n",
    "    test_size = (4,3)\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.6, pytest-3.8.2, py-1.6.0, pluggy-0.7.1 -- /usr/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ubuntu/jupyter_notebooks/Michele_Pellegrino/MilanoGPU2018/notebooks, inifile:\n",
      "collecting ... collected 1 item\n",
      "\n",
      "MatrixVectorTesting.py::test_gpuMatrixVector <- <ipython-input-9-f218d36f4ccb> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocation: 0.607967 ms\n",
      "Upload: 0.397682 ms\n",
      "Execution: 0.153780 ms\n",
      "Allocation: 0.591278 ms\n",
      "Upload: 0.412703 ms\n",
      "Execution: 0.571728 ms\n",
      "Allocation: 0.473261 ms\n",
      "Upload: 0.475407 ms\n",
      "Execution: 0.191212 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED [100%]\n",
      "\n",
      "=========================== 1 passed in 0.04 seconds ===========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pytest(filename='MatrixVectorTesting.ipynb', pytest_options=['-vvv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_gpuMatrixVector(dim_char):\n",
    "    # Test matrix\n",
    "    a = np.ones((dim_char,dim_char), dtype=np.float32)\n",
    "    b = np.ones((dim_char,1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocation: 0.409365 ms\n",
      "Upload: 1.056194 ms\n",
      "Execution: 0.105858 ms\n",
      "My Timer Tag: 5.189896 ms\n",
      "Allocation: 0.336647 ms\n",
      "Upload: 0.486612 ms\n",
      "Execution: 0.087976 ms\n",
      "My Timer Tag: 3.832340 ms\n",
      "Allocation: 0.449419 ms\n",
      "Upload: 0.189781 ms\n",
      "Execution: 0.464678 ms\n",
      "My Timer Tag: 11.790991 ms\n",
      "Allocation: 2.231121 ms\n",
      "Upload: 2.360106 ms\n",
      "Execution: 0.811338 ms\n",
      "My Timer Tag: 21.872520 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block size is (128, 1, 1)\n",
      "Grid size is (1, 1, 1)\n",
      "It took 0.0051898956298828125 seconds\n",
      "Block size is (128, 1, 1)\n",
      "Grid size is (1, 1, 1)\n",
      "It took 0.0038323402404785156 seconds\n",
      "Block size is (128, 1, 1)\n",
      "Grid size is (1, 1, 1)\n",
      "It took 0.011790990829467773 seconds\n",
      "Block size is (128, 1, 1)\n",
      "Grid size is (8, 1, 1)\n",
      "It took 0.021872520446777344 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocation: 1.113653 ms\n",
      "Upload: 49.981117 ms\n",
      "Execution: 29.795885 ms\n",
      "My Timer Tag: 454.941273 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block size is (128, 1, 1)\n",
      "Grid size is (79, 1, 1)\n",
      "It took 0.4549412727355957 seconds\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 10, 100, 1000, 10000]:\n",
    "    with Timer(\"My Timer Tag\", logging.INFO) as t:\n",
    "        timing_gpuMatrixVector(k)\n",
    "    print(\"It took \" + str(t.secs) + \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
